{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Deep-MacroFin","text":"<p>Deep-MacroFin is a comprehensive deep-learning framework designed to solve partial differential equations, with a particular focus on models in continuous time economics.  It is heavily inspired from PyMacroFin[^1] and DeepXDE[^2] </p>"},{"location":"#installation","title":"Installation","text":""},{"location":"#install-from-pypi","title":"Install from PyPI","text":""},{"location":"#build-from-source","title":"Build from Source","text":"<p>[^1]: Adrien d'Avernas and Damon Petersen and Quentin Vandeweyer, \"Macro-financial Modeling in Python: PyMacroFin\", 2021-11-18 [^2]: Lu, Lu and Meng, Xuhui and Mao, Zhiping and Karniadakis, George Em, \"DeepXDE: A deep learning library for solving differential equations\", SIAM Review, 63(1): 208\u2013228, 2021</p>"},{"location":"api/evaluations/","title":"deep_macrofin.evaluations","text":""},{"location":"api/evaluations/#formula","title":"Formula","text":"<p>Base class for string evaluations</p>"},{"location":"api/evaluations/#comparator","title":"Comparator","text":""},{"location":"api/evaluations/#baseconditions","title":"BaseConditions","text":""},{"location":"api/evaluations/#agentconditions","title":"AgentConditions","text":""},{"location":"api/evaluations/#endogvarconditions","title":"EndogVarConditions","text":""},{"location":"api/evaluations/#constraint","title":"Constraint","text":""},{"location":"api/evaluations/#endogequation","title":"EndogEquation","text":""},{"location":"api/evaluations/#equation","title":"Equation","text":""},{"location":"api/evaluations/#hjbequation","title":"HJBEquation","text":""},{"location":"api/evaluations/#system","title":"System","text":""},{"location":"api/models/","title":"deep_macrofin.models","text":""},{"location":"api/models/#learnablevar","title":"LearnableVar","text":"<p><pre><code>class LearnableVar(name: str, state_variables: List[str], config: Dict[str, Any])\n</code></pre> Inputs: - name (str): The name of the model. - state_variables (List[str]): List of state variables.  </p> <p>Config: specifies number of layers/hidden units of the neural network and highest order of derivatives to take. - device: str, the device to run the model on (e.g., \"cpu\", \"cuda\"), default will be chosen based on whether or not GPU is available - hidden_units: List[int], number of units in each layer, default: [30, 30, 30, 30] - layer_type: str, a selection from the LayerType enum, default: LayerType.MLP - activation_type: str, a selection from the ActivationType enum, default: ActivationType.Tanh - positive: bool, apply softplus to the output to be always positive if true, default: false - hardcode_function: a lambda function for hardcoded forwarding function, default: None - derivative_order: int, an additional constraint for the number of derivatives to take, so for a function with one state variable, we can still take multiple derivatives, default: number of state variables  </p> <p>Base class for </p>"},{"location":"api/models/#agent","title":"Agent","text":""},{"location":"api/models/#endogvar","title":"EndogVar","text":""},{"location":"api/models/#derivative_utils","title":"derivative_utils","text":"<pre><code>def get_derivs_1order(y, x, idx):\n</code></pre> <pre><code>def get_all_derivs(target_var_name=\"f\", all_vars: List[str] = [\"x\", \"y\", \"z\"], derivative_order = 2) -&gt; Dict[str, Callable]:\n</code></pre>"},{"location":"api/models/#constants","title":"Constants","text":"<pre><code>class LearnableModelType(str, Enum):\n    Agent=\"Agent\"\n    EndogVar=\"EndogVar\"\n\nclass LayerType(str, Enum):\n    MLP=\"MLP\"\n    KAN=\"KAN\"\n\nclass ActivationType(str, Enum):\n    ReLU=\"relu\"\n    SiLU=\"silu\"\n    Sigmoid=\"sigmoid\"\n    Tanh=\"tanh\"\n</code></pre>"},{"location":"api/pde_model/","title":"deep_macrofin.pde_model","text":"<p>This is the main interface to construct the PDE system to solve.</p>"},{"location":"api/pde_model/#pdemodel","title":"PDEModel","text":""},{"location":"api/utils/","title":"deep_macrofin.utils","text":""},{"location":"api/utils/#set_seeds","title":"set_seeds","text":""},{"location":"api/utils/#plot_loss_df","title":"plot_loss_df","text":""},{"location":"api/utils/#constants","title":"Constants","text":"<pre><code>DEFAULT_CONFIG = {\n    \"batch_size\": 100,\n    \"num_epochs\": 1000,\n    \"lr\": 1e-3,\n    \"loss_log_interval\": 100,\n    \"optimizer_type\": OptimizerType.AdamW,\n}\n\nDEFAULT_LEARNABLE_VAR_CONFIG = {\n    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n    \"hidden_units\": [30, 30, 30, 30],\n    \"layer_type\": LayerType.MLP,\n    \"activation_type\": ActivationType.Tanh,\n    \"positive\": False,\n    \"derivative_order\": 2,\n}\n</code></pre>"},{"location":"examples/approx/discont/","title":"Discontinuous and Oscillating Function","text":"<p>The full solution can be found at function_approximation.ipynb.</p>"},{"location":"examples/approx/discont/#problem-setup","title":"Problem Setup","text":"\\[ y= \\begin{cases}      5 + \\sum_{k=1}^4 \\sin(kx), x&lt;0\\\\     \\cos(10x), x\\geq 0  \\end{cases} \\]"},{"location":"examples/odes/basic_ode1/","title":"Base ODE 1","text":"<p>The full solution can be found at basic_odes.ipynb.</p>"},{"location":"examples/odes/basic_ode1/#problem-setup","title":"Problem Setup","text":"\\[\\frac{dx}{dt} = 2t, x(0)=1\\] <p>The solution is \\(x(t)=t^2+1\\)</p>"},{"location":"examples/odes/basic_ode1/#implementation","title":"Implementation","text":"<ol> <li> <p>Import necessary packages <pre><code>import os\nimport numpy as np\nimport torch\nimport matplotlib.pyplot as plt\nfrom deep_macrofin import PDEModel\nfrom deep_macrofin import ActivationType, Comparator, EndogVar, EndogVarConditions, EndogEquation\n</code></pre></p> </li> <li> <p>Define problem. <pre><code>ode1 = PDEModel(\"ode1\") # define PDE model to solve\node1.set_state([\"t\"], {\"t\": [-2., 2.]}) # set the state variable, which defines the dimensionality of the problem\node1.add_endog(\"x\") # we use endogenous variable to represent the function we want to approximate\node1.add_endog_equation(r\"$\\frac{\\partial x}{\\partial t} = 2 * t$\", label=\"base_ode\") # endogenous equations are used to represent the ODE\node1.add_endog_condition(\"x\", \n                              \"x(SV)\", {\"SV\": torch.zeros((1, 1))},\n                              Comparator.EQ,\n                              \"1\", {},\n                              label=\"initial_condition\") # define initial condition\n</code></pre></p> </li> <li> <p>Train and evaluate <pre><code>ode1.train_model(\"./models/ode1\", \"ode1.pt\", True)\node1.eval_model(True)\n</code></pre></p> </li> <li> <p>To load a trained model <pre><code>ode1.load_model(torch.load(\"./models/ode1/ode1.pt\"))\n</code></pre></p> </li> <li> <p>Plot the solutions <pre><code>fig, ax = plt.subplots(1, 3, figsize=(16, 5))\nt = np.linspace(-2, 2)\nax[0].plot(t, t**2+1, label=\"t^2+1\")\nax[1].plot(t, 2*t, label=\"2*t\")\nax[2].plot(t, np.ones_like(t) * 2, label=\"2\")\node1.endog_vars[\"x\"].plot(\"x\", {\"t\": [-2, 2]}, ax=ax[0])\node1.endog_vars[\"x\"].plot(\"x_t\", {\"t\": [-2, 2]}, ax=ax[1])\node1.endog_vars[\"x\"].plot(\"x_tt\", {\"t\": [-2, 2]}, ax=ax[2])\nplt.subplots_adjust()\nplt.show()\n</code></pre></p> </li> </ol>"},{"location":"examples/pdes/laplace/","title":"Laplace Equation Dirichlet Problem","text":"<p>The full solution can be found at basic_pdes.ipynb.</p>"},{"location":"examples/pdes/laplace/#problem-setup","title":"Problem Setup","text":"\\[\\nabla^2 T = \\frac{\\partial^2 T}{\\partial x^2} + \\frac{\\partial^2 T}{\\partial y^2} = 0, T(x,0)=T(x,\\pi)=0, T(0,y)=1\\] <p>The solution is \\(T(x,y) = \\frac{2}{\\pi} \\arctan\\frac{\\sin y}{\\sinh x}\\)</p>"},{"location":"examples/pdes/laplace/#implementation","title":"Implementation","text":""},{"location":"examples/pymacrofin/log_utility/","title":"Log Utility Problem","text":"<p>The full solution can be found at 1d_problem.ipynb.</p>"},{"location":"examples/pymacrofin/log_utility/#problem-setup","title":"Problem Setup","text":"<p>This is Proposition 4 from Brunnermeier and Sannikov 2014[^1]</p> <p>[^1]: Brunnermeier, Markus K. and Sannikov, Yuliy, \"A Macroeconomic Model with a Financial Sector\", SIAM Review, 104(2): 379\u2013421, 2014</p>"}]}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2617228f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Neoclassical Growth model\n",
    "\n",
    "Finite difference method adapted from https://benjaminmoll.com/codes/ HJB_NGM.m\n",
    "'''\n",
    "import os\n",
    "import time\n",
    "from typing import Dict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from deep_macrofin import (Comparator, OptimizerType, PDEModel,\n",
    "                           PDEModelTimeStep, set_seeds)\n",
    "\n",
    "\n",
    "plt.rcParams[\"font.size\"] = 20\n",
    "plt.rcParams[\"lines.linewidth\"] = 3\n",
    "plt.rcParams[\"lines.markersize\"] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9e39ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def utility(c, gamma):\n",
    "    if gamma == 1:\n",
    "        return np.log(c)\n",
    "    else:\n",
    "        return c**(1-gamma)/(1-gamma)\n",
    "\n",
    "def utility_deriv(c, gamma):\n",
    "    if gamma == 1:\n",
    "        return 1 / c\n",
    "    else:\n",
    "        return c**(-gamma)\n",
    "\n",
    "def inverse_marginal_deriv(dV, gamma):\n",
    "    if gamma == 1:\n",
    "        return 1 / dV\n",
    "    else:\n",
    "        return dV**(-1/gamma)\n",
    "\n",
    "def solve_upwind(gamma, alpha, delta, rho, A, N, max_iter=10000, crit=1e-6):\n",
    "    '''\n",
    "    Inputs:\n",
    "    - gamma: risk aversion\n",
    "    - alpha: capital share\n",
    "    - delta: depreciation\n",
    "    - rho: discount rate\n",
    "    - A: productivity\n",
    "    - N: grid count\n",
    "    - max_iter: maximum number of iterations\n",
    "    - crit: error threshold\n",
    "    '''\n",
    "    kss = (alpha * A / (rho + delta)) ** (1 / (1-alpha))\n",
    "    print(kss)\n",
    "    kmin = 0.001 * kss\n",
    "    kmax = 2 * kss\n",
    "    k = np.linspace(kmin, kmax, N)\n",
    "    dk = (kmax - kmin) / (N - 1)\n",
    "\n",
    "    dVf = np.zeros(N)\n",
    "    dVb = np.zeros(N)\n",
    "    c = np.zeros(N)\n",
    "\n",
    "    # Initial guess\n",
    "    c0 = A * k ** alpha\n",
    "    v0 = utility(c0, gamma) / rho\n",
    "    v = v0.copy()\n",
    "\n",
    "    dist = np.zeros(max_iter)\n",
    "    for n in range(max_iter):\n",
    "        V = v.copy()\n",
    "\n",
    "        # Forward difference\n",
    "        dVf[:-1] = (V[1:] - V[:-1]) / dk\n",
    "        dVf[-1] = 0  # Never used\n",
    "\n",
    "        # Backward difference\n",
    "        dVb[1:] = (V[1:] - V[:-1]) / dk\n",
    "        dVb[0] = 0  # Never used\n",
    "\n",
    "        I_concave = dVb > dVf\n",
    "\n",
    "        # Consumption and savings\n",
    "        cf = inverse_marginal_deriv(dVf, gamma)\n",
    "        muf = A * k ** alpha - delta * k - cf\n",
    "\n",
    "        cb = inverse_marginal_deriv(dVb, gamma)\n",
    "        mub = A * k ** alpha - delta * k - cb\n",
    "\n",
    "        c0 = A * k ** alpha - delta * k\n",
    "        dV0 = c0 ** (-gamma)\n",
    "\n",
    "        # Upwind scheme\n",
    "        If = muf > 0\n",
    "        Ib = mub < 0\n",
    "        I0 = ~(If | Ib)\n",
    "\n",
    "        Ib[0] = False\n",
    "        If[0] = True\n",
    "        Ib[-1] = True\n",
    "        If[-1] = False\n",
    "\n",
    "        dV_Upwind = dVf * If + dVb * Ib + dV0 * I0\n",
    "\n",
    "        c = inverse_marginal_deriv(dV_Upwind, gamma)\n",
    "        Vchange = utility(c, gamma) + dV_Upwind * (A * k ** alpha - delta * k - c) - rho * V\n",
    "\n",
    "        # Update\n",
    "        DeltaT = 0.9 * dk / np.max(A * k ** alpha - delta * k)\n",
    "        v += DeltaT * Vchange\n",
    "\n",
    "        dist[n] = np.max(np.abs(Vchange))\n",
    "        if dist[n] < crit:\n",
    "            print(f'Value Function Converged, Iteration = {n}')\n",
    "            break\n",
    "    return k, v, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccefb96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(params: Dict[str, float], training_config: Dict[str, Dict], model_configs: Dict[str, Dict], seed=0, init_guess={\"V\": -18, \"c\": 1.5}):\n",
    "    kss = (params[\"alpha\"] / (params[\"rho\"] + params[\"delta\"])) ** (1 / (1 - params[\"alpha\"]))\n",
    "    ckss = kss**params[\"alpha\"] - params[\"delta\"] * kss\n",
    "    set_seeds(seed)\n",
    "    model = PDEModelTimeStep(\"ncg\", config=training_config)\n",
    "    model.set_state([\"k\"], {\"k\": [0.01 * kss, 2 * kss]}) #  \n",
    "    model.add_params(params)\n",
    "    model.add_endog(\"V\", config=model_configs[\"V\"])\n",
    "    model.add_endog(\"c\", config=model_configs[\"c\"])\n",
    "    if params[\"gamma\"] == 1:\n",
    "        endog_cond = torch.log(torch.tensor(ckss, dtype=torch.float32, device=model.device))/params[\"rho\"]\n",
    "        utility_eq = \"u=log(c)\"\n",
    "    else:\n",
    "        endog_cond = ckss**(1-params[\"gamma\"]) / ((1-params[\"gamma\"]) * params[\"rho\"])\n",
    "        utility_eq = \"u=c**(1-gamma)/(1-gamma)\"\n",
    "    \n",
    "    ss_bd = torch.zeros((100, 2), device=model.device)\n",
    "    ss_bd[:, 0] = kss\n",
    "    ss_bd[:, 1] = torch.linspace(0, 1, 100, device=model.device)\n",
    "    model.add_endog_condition(\"V\", \n",
    "                                \"V(SV)\", \n",
    "                                {\"SV\": ss_bd},\n",
    "                                Comparator.EQ,\n",
    "                                \"ec\", {\"ec\": endog_cond},\n",
    "                                label=\"v1\")\n",
    "    model.add_endog_condition(\"c\", \n",
    "                                \"c(SV)\", \n",
    "                                {\"SV\": ss_bd},\n",
    "                                Comparator.EQ,\n",
    "                                \"kss**alpha - delta * kss\", params | {\"kss\": kss},\n",
    "                                label=\"c1\")\n",
    "    model.add_equation(\"s=k**alpha - delta * k - c\")\n",
    "    model.add_equation(utility_eq)\n",
    "    model.add_endog_equation(\"c**(-gamma)=V_k\")\n",
    "    model.add_constraint(\"c_k\", Comparator.GEQ, \"0\")\n",
    "    model.add_hjb_equation(\"V_t + u+ V_k * s-rho*V\")\n",
    "    model.set_initial_guess(init_guess)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4887c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS = {\n",
    "        \"gamma\": 2, # Risk aversion\n",
    "        \"alpha\": 0.3, # Returns to scale\n",
    "        \"delta\": 0.05, # Capital depreciation\n",
    "        \"rho\": 0.05, # Discount rate\n",
    "        \"A\": 1, # Productivity\n",
    "    }\n",
    "kss = (PARAMS[\"alpha\"] / (PARAMS[\"rho\"] + PARAMS[\"delta\"])) ** (1 / (1 - PARAMS[\"alpha\"]))\n",
    "\n",
    "TRAINING_CONFIGS = {\n",
    "    \"MLP\": {\"num_outer_iterations\": 20, \"num_inner_iterations\": 10000,  \n",
    "            \"time_batch_size\": 5, \"optimizer_type\": OptimizerType.Adam},\n",
    "}\n",
    "\n",
    "MODEL_CONFIGS = {\n",
    "    \"MLP\": {\n",
    "        \"V\": {\"hidden_units\": [64] * 4},\n",
    "        \"c\": {\"hidden_units\": [32] * 4, \"positive\": True},\n",
    "    },\n",
    "}\n",
    "\n",
    "INIT_GUESSES = {\"V\": -18, \"c\": 1.5}\n",
    "\n",
    "BASE_DIR = \"models/ncg_ts/\"\n",
    "os.makedirs(BASE_DIR, exist_ok=True)\n",
    "print(\"{0:=^80}\".format(\"loading FD solutions\"))\n",
    "if not os.path.exists(f\"{BASE_DIR}/ncg_fd.npz\"):\n",
    "    k, v, c = solve_upwind(PARAMS[\"gamma\"], PARAMS[\"alpha\"], PARAMS[\"delta\"], \n",
    "                        PARAMS[\"rho\"], PARAMS[\"A\"], 100)\n",
    "    np.savez(f\"{BASE_DIR}/ncg_fd.npz\", k=k, v=v, c=c)\n",
    "fd_res = np.load(f\"{BASE_DIR}/ncg_fd.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1036a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(PARAMS, TRAINING_CONFIGS, MODEL_CONFIGS, 0)\n",
    "if not os.path.exists(f\"{BASE_DIR}/model.pt\"):\n",
    "    model.train_model(BASE_DIR, f\"model.pt\", True)\n",
    "    model.eval_model(True)\n",
    "else:\n",
    "    model.load_model(torch.load(f\"{BASE_DIR}/model.pt\", weights_only=False, map_location=model.device))\n",
    "    model.eval_model(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a185e8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fd = fd_res[\"k\"]\n",
    "v_fd = fd_res[\"v\"]\n",
    "c_fd = fd_res[\"c\"]\n",
    "idx = k_fd > 0.01 * kss\n",
    "k_fd = k_fd[idx]\n",
    "v_fd = v_fd[idx]\n",
    "c_fd = c_fd[idx]\n",
    "\n",
    "SV = torch.zeros((k_fd.shape[0], 2), device=model.device)\n",
    "SV[:, 0] = torch.tensor(k_fd, device=model.device, dtype=torch.float32)\n",
    "for i, sv_name in enumerate(model.state_variables):\n",
    "    model.variable_val_dict[sv_name] = SV[:, i:i+1]\n",
    "model.variable_val_dict[\"SV\"] = SV\n",
    "model.update_variables(SV)\n",
    "V_model = model.variable_val_dict[\"V\"].detach().cpu().numpy().reshape(-1)\n",
    "c_model = model.variable_val_dict[\"c\"].detach().cpu().numpy().reshape(-1)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "ax[0].plot(k_fd, v_fd, linestyle=\"-.\", color=\"red\", label=\"Finite Difference\")\n",
    "ax[0].plot(k_fd, V_model, color=\"blue\", label=f\"Deep-MacroFin\")\n",
    "ax[0].legend()\n",
    "ax[0].set_xlabel(\"$k$\")\n",
    "ax[0].set_ylabel(\"$V(k)$\")\n",
    "\n",
    "ax[1].plot(k_fd, c_fd, linestyle=\"-.\", color=\"red\", label=\"Finite Difference\")\n",
    "ax[1].plot(k_fd, c_model, color=\"blue\", label=f\"Deep-MacroFin\")\n",
    "ax[1].legend()\n",
    "ax[1].set_xlabel(\"$k$\")\n",
    "ax[1].set_ylabel(\"$c(k)$\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
